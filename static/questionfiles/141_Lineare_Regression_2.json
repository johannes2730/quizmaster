{
  "title": "Lineare Regression",
  "questions": [
    {
      "question": "Wozu dienen Regressionsmodelle?",
      "answer": "Regressionsmodelle helfen, Trends zu identifizieren, Muster zu erkennen und Vorhersagen über zukünftige Werte zu treffen."
    },
    {
      "question": "Warum sind Regressionsmodelle auch ohne Vorhersage-Ziel interessant?",
      "answer": "Regressionsmodelle sind nicht nur zur Vorhersage nützlich, sondern auch zur Interpretation und zum Verständnis von Zusammenhängen zwischen Variablen."
    },
    {
      "question": "Zur Bewertung von Regressionsmodellen werden außerdem Metriken verwendet. Welche Metriken sind populär und was sagen sie aus?",
      "answer": {
        "R2": "Misst, wie viel der Varianz der Zielvariable durch das Modell erklärt wird (Erklärte Varianz).",
        "MAE": "Gibt den durchschnittlichen absoluten Fehler an – also wie stark die Vorhersagen im Schnitt abweichen.",
        "MSE": "Ist der mittlere quadratische Fehler – große Fehler werden stärker bestraft als kleine.",
        "RMSE": "Ist die Quadratwurzel des MSE – besser interpretierbar, da die Einheit wieder der Zielgröße entspricht."
      }
    },
    {
      "question": "Regressionsmodelle bewerten: Worin unterscheiden sich MAE, R2, MSE, RMSE und was haben sie gemeinsam?",
      "answer": "Alle Metriken messen auf unterschiedliche Weise die Genauigkeit von Vorhersagen. MAE misst den durchschnittlichen absoluten Fehler, MSE und RMSE bestrafen größere Fehler stärker, während R2 angibt, wie gut das Modell die Zielvariable erklärt. Gemeinsam ist ihnen, dass sie alle quantitative Aussagen über die Modellgüte machen."
    }
  ]
}
